# WEB_SCRAPPING_FROM_SCRATCH
This project is a web scraping implementation in Python to extract information about Asian countries and regions from a Wikipedia page. The script retrieves valuable data, such as area statistics, from the specified Wikipedia page, providing a structured dataset for analysis and visualization.
Features
Scraping: Utilizes the BeautifulSoup library for efficient web scraping.
Data Extraction: Gathers information on areas and nations within the Asian continent.
Structured Dataset: Outputs a well-organized dataset in CSV format for easy integration into data analytics tools.
Documentation: Includes comprehensive documentation to guide users on running and understanding the code.
How to Use
Clone the repository to your local machine.
Install the required dependencies using pip install -r requirements.txt.
Run the scraper.py script to initiate the web scraping process.
Find the extracted data in the output directory in CSV format.
Dependencies
BeautifulSoup: For parsing HTML and XML documents.
Requests: For making HTTP requests.
Contributions
Contributions are welcome! Feel free to open issues, submit pull requests, or provide feedback.
